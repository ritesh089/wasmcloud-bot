# wasmCloud RAG Bot - Environment Configuration
# Copy this file to .env and update the values below

# OpenAI API Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Database Configuration (PostgreSQL with pgvector)
# These values match the docker-compose.yml configuration
DATABASE_URL=postgresql://wasmcloud_user:wasmcloud_password@localhost:5432/wasmcloud_rag
PGVECTOR_HOST=localhost
PGVECTOR_PORT=5432
PGVECTOR_DB=wasmcloud_rag
PGVECTOR_USER=wasmcloud_user
PGVECTOR_PASSWORD=wasmcloud_password

# Server Configuration
# Port for the MCP server (if using MCP integration)
MCP_SERVER_PORT=8001
# Port for the main FastAPI server
PORT=8000

# AI Model Configuration
# OpenAI embedding model for vector generation
EMBEDDING_MODEL=text-embedding-3-small
# OpenAI chat model for response generation
CHAT_MODEL=gpt-4-1106-preview

# Text Processing Configuration
# Size of text chunks for processing (in tokens)
CHUNK_SIZE=1000
# Overlap between chunks (in tokens)
CHUNK_OVERLAP=200

# Optional: Logging Configuration
LOG_LEVEL=INFO

# =============================================================================
# OPTIMIZATION FEATURES - Advanced AI-Powered Enhancements
# =============================================================================

# AI-Enhanced Chunking - Uses AI to create semantically coherent chunks
# Instead of simple token-based splitting, AI analyzes document structure
ENABLE_AI_CHUNKING=true
AI_CHUNKING_THRESHOLD=1000
AI_CHUNKING_MODEL=gpt-3.5-turbo

# Advanced RAG Features  
# Hybrid Search - Combines vector, keyword, and concept search with AI reranking
# WARNING: Enabling this will increase OpenAI API costs significantly
ENABLE_HYBRID_SEARCH=false
ENABLE_KEYWORD_SEARCH=true
ENABLE_CONCEPT_SEARCH=true
ENABLE_AI_RERANKING=true

# Search Parameters
# Number of chunks to retrieve initially before reranking
VECTOR_SEARCH_K=10
# Final number of chunks to use after reranking
FINAL_RESULTS_K=5
# Minimum similarity threshold for chunk relevance
SIMILARITY_THRESHOLD=0.6

# Performance Settings
# Number of embeddings to generate in parallel
EMBEDDING_BATCH_SIZE=10
# Cache embeddings to reduce API calls
CACHE_EMBEDDINGS=true

# Cost Management
# Maximum number of AI API calls per query (to control costs)
MAX_AI_CALLS_PER_QUERY=3
# Use cheaper models for analysis tasks when possible
USE_CHEAPER_MODELS=true

# Smart Document Processing (Future Enhancement)
# AI-powered content quality assessment during scraping
ENABLE_SMART_SCRAPING=false
QUALITY_THRESHOLD=0.7 